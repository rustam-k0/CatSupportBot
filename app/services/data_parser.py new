[file name]: data_parser.py
[file content begin]
import re
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

def _clean_amount_string(s: str) -> float | None:
    if not isinstance(s, str):
        return None
    try:
        cleaned = re.sub(r'[^\d,.]', '', s)
        cleaned = cleaned.replace(',', '.')
        return float(cleaned)
    except (ValueError, TypeError):
        return None

def _normalize_text_for_search(text: str) -> str:
    if not isinstance(text, str):
        return ''
    text = re.sub(r'[ \t]+', ' ', text)
    text = re.sub(r'\n+', '\n', text)
    return text.strip()

def _clean_author_string(author: str) -> str:
    author = author.strip('.,;:"¬´¬ª \n\t')
    author = re.sub(r'^(–û–û–û|–ò–ü|–ê–û|–ü–ê–û|–ó–ê–û|–û–ê–û)\s+', '', author, flags=re.IGNORECASE).strip()
    author = author.strip('"¬´¬ª')
    if not author.endswith('.'):
        author += '.'
    return author

def parse_multiple_transactions(text: str) -> list[dict]:
    """
    –ü–∞—Ä—Å–∏—Ç –±–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–æ—Ö–æ–¥–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π —Å–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞.
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∞ –¢-–ë–∞–Ω–∫–∞ —Å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏.
    """
    logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π. –û–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤.")
    
    bank = parse_bank(text)
    transactions = []
    
    # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¢-–ë–∞–Ω–∫–∞
    amount_pattern = re.compile(r'\+\s*([\d\s,.]*)\s*(?:‚ÇΩ|–†|P)', re.IGNORECASE)
    author_pattern = re.compile(r'^[–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å]\.$')
    
    lines = text.split('\n')
    i = 0
    
    while i < len(lines):
        line = lines[i].strip()
        
        # –ò—â–µ–º —Å—É–º–º—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        amount_match = amount_pattern.search(line)
        if amount_match:
            amount_str = amount_match.group(1)
            amount = _clean_amount_string(amount_str)
            
            if amount:
                # –ò—â–µ–º –∞–≤—Ç–æ—Ä–∞ –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö
                author = None
                
                # –ü–æ–∏—Å–∫ –≤–≤–µ—Ä—Ö –ø–æ —Å—Ç—Ä–æ–∫–∞–º (–º–∞–∫—Å–∏–º—É–º 5 —Å—Ç—Ä–æ–∫)
                for j in range(1, 6):
                    if i - j >= 0:
                        prev_line = lines[i - j].strip()
                        if author_pattern.match(prev_line):
                            author = _clean_author_string(prev_line)
                            break
                
                # –ï—Å–ª–∏ –∞–≤—Ç–æ—Ä –Ω–∞–π–¥–µ–Ω –∏ —Å—É–º–º–∞ –≤–∞–ª–∏–¥–Ω–∞ - –¥–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é
                if author and amount > 0:
                    transactions.append({
                        'author': author,
                        'amount': amount,
                        'bank': bank if bank else "–¢-–ë–∞–Ω–∫"
                    })
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
                    i += 3
                    continue
        
        i += 1

    logger.info(f"üìä –ü–∞—Ä—Å–∏–Ω–≥ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω. –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {len(transactions)} –∑–∞–ø–∏—Å–µ–π.")
    return transactions

# –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
def _get_date_patterns() -> list:
    return [
        {
            'tier': 0,
            'desc': '–î–∞—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –≤—Ä–µ–º–µ–Ω–µ–º (—Ç–µ–∫—Å—Ç–æ–≤–∞—è, —Å –∫–ª—é—á–æ–º)',
            'regex': r'(?:–û–ø–µ—Ä–∞—Ü–∏—è\s+—Å–æ–≤–µ—Ä—à–µ–Ω–∞|–î–∞—Ç–∞\s+–æ–ø–µ—Ä–∞—Ü–∏–∏|–¢–æ–≤–∞—Ä–Ω—ã–π\s—á–µ–∫\s.*?–∑–∞)[:\s]*(\d{1,2})\s+(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)\s+(\d{4})',
            'type': 'textual_ru',
            'flags': re.IGNORECASE
        },
        # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–∞—Ç –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    ]

def _get_amount_patterns() -> list:
    AMOUNT_REGEX = r'(\d(?:\s?\d)*(?:[,.]\d{1,2})?)'
    CURRENCY_REGEX = r'(?:–†|‚ÇΩ|—Ä—É–±\.?|RUB|P)'
    return [
        {'tier': 0, 'desc': '–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ "–ò—Ç–æ–≥–æ —Å—É–º–º–∞ —á–µ–∫–∞"', 'regex': fr'(?:–ò—Ç–æ–≥–æ\s—Å—É–º–º–∞\s—á–µ–∫–∞)\s*[:\s.]*\s*{AMOUNT_REGEX}', 'flags': re.IGNORECASE},
        # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å—É–º–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    ]

def _get_bank_patterns() -> list:
    BANK_KEYWORDS = {
        '–¢-–ë–∞–Ω–∫': ['—Ç-–±–∞–Ω–∫', '—Ç–±–∞–Ω–∫', '—Ç–∏–Ω—å–∫–æ—Ñ—Ñ', 'tinkoff', 't-bank'],
        '–°–±–µ—Ä–±–∞–Ω–∫': ['—Å–±–µ—Ä–±–∞–Ω–∫', '—Å–±–µ—Ä', 'sber', 'sberbank'],
        '–ê–ª—å—Ñ–∞-–ë–∞–Ω–∫': ['–∞–ª—å—Ñ–∞-–±–∞–Ω–∫', '–∞–ª—å—Ñ–∞', 'alfa', 'alfabank'],
        '–í–¢–ë': ['–≤—Ç–±', 'vtb'],
        '–Ø–Ω–¥–µ–∫—Å': ['—è–Ω–¥–µ–∫—Å', 'yandex'],
    }
    patterns = []
    for bank_name, keywords in BANK_KEYWORDS.items():
        regex = r'\b(' + '|'.join(keywords) + r')\b'
        patterns.append({'tier': 1, 'desc': f'–ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –¥–ª—è "{bank_name}"', 'regex': regex, 'bank_name': bank_name, 'flags': re.IGNORECASE})
    return patterns

def _get_author_patterns(transaction_type: str) -> list:
    AUTHOR_NAME_REGEX = r'([–ê-–Ø–Å][–∞-—è—ëA-Za-z\s."¬´¬ª-]+?)'
    if transaction_type in ['income', 'transaction']:
        return [
            {'tier': 1, 'desc': '–ö–ª—é—á "–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å", "–ü–ª–∞—Ç–µ–ª—å—â–∏–∫", "–û—Ç –∫–æ–≥–æ"', 'regex': fr'(?:–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å|–ü–ª–∞—Ç–µ–ª—å—â–∏–∫|–û—Ç\s–∫–æ–≥–æ)\s*[:\s\n]*{AUTHOR_NAME_REGEX}(?=\n|$)', 'flags': re.IGNORECASE},
            # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∞–≤—Ç–æ—Ä–æ–≤ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        ]
    else: # expense
        return [
            {'tier': 0, 'desc': '–ù–∞–∑–≤–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –≤ –Ω–∞—á–∞–ª–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–Ω–∞–¥ –∞–¥—Ä–µ—Å–æ–º)', 'regex': r'^(.*?)\n\s*(?:–ê–¥—Ä–µ—Å\s–∫–ª–∏–Ω–∏–∫–∏|–ê–¥—Ä–µ—Å)', 'flags': re.MULTILINE},
            # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∞–≤—Ç–æ—Ä–æ–≤ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        ]

def _get_comment_patterns() -> list:
    return [{'tier': 1, 'desc': '–ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º', 'regex': r'(?:–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π|–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ|–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ\s–ø–ª–∞—Ç–µ–∂–∞|Note|Comment|Description)\s*[:\s\n]*(.+?)(?=\n\n|$|\n\s*‚Äî{3,})', 'flags': re.IGNORECASE | re.DOTALL}]

def _get_procedure_patterns() -> list:
    return [{'tier': 1, 'desc': '–ë–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞ –º–µ–∂–¥—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–º —Ç–∞–±–ª–∏—Ü—ã –∏ –∏—Ç–æ–≥–æ–≤–æ–π —Å—É–º–º–æ–π', 'regex': r'(?:–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ.*?–°—Ç-—Ç—å)\s*\n(.*?)(?=\n\s*–ò—Ç–æ–≥–æ\s—Å—É–º–º–∞\s—á–µ–∫–∞)', 'flags': re.DOTALL | re.IGNORECASE}]

def parse_date(text: str) -> str | None:
    patterns = _get_date_patterns()
    MONTHS_RU = {'—è–Ω–≤–∞—Ä—è': '01', '—Ñ–µ–≤—Ä–∞–ª—è': '02', '–º–∞—Ä—Ç–∞': '03', '–∞–ø—Ä–µ–ª—è': '04', '–º–∞—è': '05', '–∏—é–Ω—è': '06', '–∏—é–ª—è': '07', '–∞–≤–≥—É—Å—Ç–∞': '08', '—Å–µ–Ω—Ç—è–±—Ä—è': '09', '–æ–∫—Ç—è–±—Ä—è': '10', '–Ω–æ—è–±—Ä—è': '11', '–¥–µ–∫–∞–±—Ä—è': '12'}
    MONTHS_EN = {'january': '01', 'february': '02', 'march': '03', 'april': '04', 'may': '05', 'june': '06', 'july': '07', 'august': '08', 'september': '09', 'october': '10', 'november': '11', 'december': '12'}

    found_dates = []
    
    for p in patterns:
        matches = list(re.finditer(p['regex'], text, p['flags']))
        for match in matches:
            try:
                dt_obj = None
                if p.get('type') == 'textual_ru':
                    day, month_name, year = match.groups()
                    month = MONTHS_RU.get(month_name.lower())
                    if month: 
                        dt_obj = datetime.strptime(f"{day}.{month}.{year}", "%d.%m.%Y")
                elif p.get('type') == 'textual_en':
                    day, month_name = match.groups()
                    month = MONTHS_EN.get(month_name.lower())
                    year = datetime.now().year
                    if month: 
                        dt_obj = datetime.strptime(f"{day}.{month}.{year}", "%d.%m.%Y")
                elif p.get('type') == 'numeric':
                    date_str = match.group(1).replace('/', '.').replace('-', '.')
                    parts = date_str.split('.')
                    year_format = "%Y" if len(parts[2]) == 4 else "%y"
                    dt_obj = datetime.strptime(date_str, f"%d.%m.{year_format}")
                if dt_obj:
                    normalized_date = dt_obj.strftime("%d.%m.%Y")
                    found_dates.append({
                        'date': normalized_date,
                        'tier': p['tier'],
                        'match_text': match.group(0),
                        'position': match.start()
                    })
            except (ValueError, IndexError) as e:
                continue

    if found_dates:
        best_date = min(found_dates, key=lambda x: (x['tier'], x['position']))
        return best_date['date']
    
    return None

def parse_amount(text: str, transaction_type: str) -> float | None:
    patterns = _get_amount_patterns()
    for p in patterns:
        match = re.search(p['regex'], text, p['flags'])
        if match:
            amount_str = match.groups()[-1]
            amount = _clean_amount_string(amount_str)
            if amount and amount > 0:
                return amount
    return None

def parse_bank(text: str) -> str | None:
    patterns = _get_bank_patterns()
    search_text = text.lower()
    for p in patterns:
        if re.search(p['regex'], search_text, p['flags']):
            bank_name = p['bank_name']
            return bank_name
    return None

def parse_author(text: str, transaction_type: str) -> str | None:
    patterns = _get_author_patterns(transaction_type)
    STOPWORDS = ['—É–ª–∏—Ü–∞', '–º–æ—Å–∫–≤–∞', '—Ä–æ—Å—Å–∏—è', '–∫–∞—Å—Å–∏—Ä', '—á–µ–∫', '–¥–æ–∫—É–º–µ–Ω—Ç',
                 '–æ–ø–µ—Ä–∞—Ü–∏—è', '–ø–ª–∞—Ç–µ–∂', '–∫–∞—Ä—Ç–∞', '—Å—á–µ—Ç', 'transaction', '—É—Å–ø–µ—à–Ω–æ']
    for p in patterns:
        matches = list(re.finditer(p['regex'], text, p['flags']))
        for match in matches:
            author = ' '.join(filter(None, match.groups())).strip()
            author = _clean_author_string(author)
            if len(author) < 2 or len(author) > 50: continue
            if any(stop in author.lower() for stop in STOPWORDS): continue
            if re.fullmatch(r'[\d\s.,]+', author): continue
            return author
    return None

def parse_comment(text: str) -> str | None:
    patterns = _get_comment_patterns()
    for p in patterns:
        match = re.search(p['regex'], text, p['flags'])
        if match:
            comment = match.group(1).strip().replace('\n', ' ')
            if len(comment) > 2:
                comment = comment[:200] + '...' if len(comment) > 200 else comment
                return comment
    return None

def parse_procedure(text: str) -> str | None:
    patterns = _get_procedure_patterns()
    for p in patterns:
        match = re.search(p['regex'], text, p['flags'])
        if match:
            procedures_block = match.group(1).strip()
            clean_lines = []
            
            for line in procedures_block.split('\n'):
                line = line.strip()
                if not line:
                    continue
                
                cleaned_line = re.sub(r'[\s\d,.]+(—Ä—É–±\.?)?$', '', line).strip()
                cleaned_line = re.sub(r'\s*\([^)]*\)', '', cleaned_line).strip()
                
                if len(cleaned_line) > 2 and re.search(r'[–∞-—è–ê-–Ø]', cleaned_line):
                    clean_lines.append(cleaned_line)
            
            if clean_lines:
                result = '; '.join(clean_lines)
                return result
    return None

def parse_transaction_data(text: str, transaction_type: str) -> dict:
    logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥. –¢–∏–ø: {transaction_type.upper()}. –û–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤.")
    
    result = {
        "date": parse_date(text),
        "amount": parse_amount(text, transaction_type),
    }

    if transaction_type in ['income', 'transaction']:
        normalized_text = _normalize_text_for_search(text)
        result['bank'] = parse_bank(normalized_text)
        result['author'] = parse_author(normalized_text, transaction_type)
        result['comment'] = parse_comment(normalized_text)
    else: # expense
        result['procedure'] = parse_procedure(text)
        result['author'] = parse_author(text, transaction_type)
        result['comment'] = parse_comment(text)

    filled_fields = sum(1 for v in result.values() if v is not None)
    total_fields = len(result)
    logger.info(
        f"üìä –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. "
        f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ –ø–æ–ª–µ–π: {filled_fields}/{total_fields}. "
        f"–ò—Ç–æ–≥: {result}"
    )
    return result
[file content end]