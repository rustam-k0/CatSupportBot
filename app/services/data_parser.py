import re
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

def _clean_amount_string(s: str) -> float | None:
    if not isinstance(s, str):
        return None
    try:
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ, –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä, –∑–∞–ø—è—Ç—ã—Ö –∏ —Ç–æ—á–µ–∫. –ü—Ä–æ–±–µ–ª—ã —Ç–æ–∂–µ —É–±–∏—Ä–∞–µ–º.
        cleaned = re.sub(r'[^\d,.]', '', s)
        # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ float
        cleaned = cleaned.replace(',', '.')
        return float(cleaned)
    except (ValueError, TypeError):
        return None

def _normalize_text_for_search(text: str) -> str:
    if not isinstance(text, str):
        return ''
    text = re.sub(r'[ \t]+', ' ', text)
    text = re.sub(r'\n+', '\n', text)
    return text.strip()

def _clean_author_string(author: str) -> str:
    author = author.strip('.,;:"¬´¬ª \n\t')
    author = re.sub(r'^(–û–û–û|–ò–ü|–ê–û|–ü–ê–û|–ó–ê–û|–û–ê–û)\s+', '', author, flags=re.IGNORECASE).strip()
    author = author.strip('"¬´¬ª')
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫—É –≤ –∫–æ–Ω—Ü–µ, –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç, –¥–ª—è —É–Ω–∏—Ñ–∏–∫–∞—Ü–∏–∏
    if not author.endswith('.'):
        author += '.'
    return author

def _get_date_patterns() -> list:
    return [
        {
            'tier': 0,
            'desc': '–î–∞—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –≤—Ä–µ–º–µ–Ω–µ–º (—Ç–µ–∫—Å—Ç–æ–≤–∞—è, —Å –∫–ª—é—á–æ–º)',
            'regex': r'(?:–û–ø–µ—Ä–∞—Ü–∏—è\s+—Å–æ–≤–µ—Ä—à–µ–Ω–∞|–î–∞—Ç–∞\s+–æ–ø–µ—Ä–∞—Ü–∏–∏|–¢–æ–≤–∞—Ä–Ω—ã–π\s—á–µ–∫\s.*?–∑–∞)[:\s]*(\d{1,2})\s+(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)\s+(\d{4})',
            'type': 'textual_ru',
            'flags': re.IGNORECASE
        },
        {
            'tier': 0,
            'desc': '–î–∞—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –≤—Ä–µ–º–µ–Ω–µ–º (—á–∏—Å–ª–æ–≤–∞—è, —Å –∫–ª—é—á–æ–º)',
            'regex': r'(?:–û–ø–µ—Ä–∞—Ü–∏—è\s+—Å–æ–≤–µ—Ä—à–µ–Ω–∞|–î–∞—Ç–∞\s+–æ–ø–µ—Ä–∞—Ü–∏–∏)[:\s]*(\d{2}[./-]\d{2}[./-]\d{2,4})(?:\s+–≤\s+\d{1,2}:\d{2})?',
            'type': 'numeric',
            'flags': re.IGNORECASE
        },
        {
            'tier': 1,
            'desc': '–î–∞—Ç–∞ —Ä—è–¥–æ–º —Å —Å—É–º–º–æ–π –∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–º',
            'regex': r'(?:–ü–µ—Ä–µ–≤–æ–¥|–ó–∞—á–∏—Å–ª–µ–Ω–∏–µ|–°–ø–∏—Å–∞–Ω–∏–µ)\s+–æ—Ç?\s*(\d{1,2})\s+(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)\s+(\d{4})',
            'type': 'textual_ru',
            'flags': re.IGNORECASE
        },
        {
            'tier': 1,
            'desc': '–î–∞—Ç–∞ —Ä—è–¥–æ–º —Å —Å—É–º–º–æ–π –∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–º (—á–∏—Å–ª–æ–≤–∞—è)',
            'regex': r'(?:–ü–µ—Ä–µ–≤–æ–¥|–ó–∞—á–∏—Å–ª–µ–Ω–∏–µ|–°–ø–∏—Å–∞–Ω–∏–µ)\s+–æ—Ç?\s*(\d{2}[./-]\d{2}[./-]\d{2,4})',
            'type': 'numeric',
            'flags': re.IGNORECASE
        },
        {
            'tier': 2,
            'desc': '–ê–Ω–≥–ª–∏–π—Å–∫–∞—è –¥–∞—Ç–∞ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º –∏ –≤—Ä–µ–º–µ–Ω–µ–º',
            'regex': r'(\d{1,2})\s+(January|February|March|April|May|June|July|August|September|October|November|December)\s*[‚Ä¢\-]\s*\d{1,2}:\d{2}',
            'type': 'textual_en',
            'flags': re.IGNORECASE
        },
        {
            'tier': 2,
            'desc': '–ê–Ω–≥–ª–∏–π—Å–∫–∞—è –¥–∞—Ç–∞ —Å –ø—Ä–æ–±–µ–ª–æ–º –∏ –≤—Ä–µ–º–µ–Ω–µ–º',
            'regex': r'(\d{1,2})\s+(January|February|March|April|May|June|July|August|September|October|November|December)\s+\d{1,2}:\d{2}',
            'type': 'textual_en',
            'flags': re.IGNORECASE
        },
        {
            'tier': 3,
            'desc': '–õ—é–±–∞—è –¥–∞—Ç–∞ –≤ —á–∏—Å–ª–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (–î–î.–ú–ú.–ì–ì–ì–ì)',
            'regex': r'\b(\d{2}[./-]\d{2}[./-]\d{2,4})\b',
            'type': 'numeric',
            'flags': 0
        },
        {
            'tier': 4,
            'desc': '–õ—é–±–∞—è –¥–∞—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (8 –æ–∫—Ç—è–±—Ä—è 2025)',
            'regex': r'(\d{1,2})\s+(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)\s+(\d{4})\b',
            'type': 'textual_ru',
            'flags': re.IGNORECASE
        },
        {
            'tier': 5,
            'desc': '–ê–Ω–≥–ª–∏–π—Å–∫–∞—è –¥–∞—Ç–∞ –±–µ–∑ –≤—Ä–µ–º–µ–Ω–∏',
            'regex': r'\b(\d{1,2})\s+(January|February|March|April|May|June|July|August|September|October|November|December)\b',
            'type': 'textual_en',
            'flags': re.IGNORECASE
        },
        {
            'tier': 6,
            'desc': '–î–∞—Ç–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞',
            'regex': r'(?:–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–æ|–°–æ–∑–¥–∞–Ω–æ|–î–∞—Ç–∞\s+—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è).*?(\d{1,2})\s+(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)\s+(\d{4})',
            'type': 'textual_ru',
            'flags': re.IGNORECASE | re.DOTALL
        },
    ]

def _get_amount_patterns() -> list:
    AMOUNT_REGEX = r'(\d(?:\s?\d)*(?:[,.]\d{1,2})?)'
    CURRENCY_REGEX = r'(?:–†|‚ÇΩ|—Ä—É–±\.?|RUB|P)'

    return [
        {'tier': 0, 'desc': '–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ "–ò—Ç–æ–≥–æ —Å—É–º–º–∞ —á–µ–∫–∞"', 'regex': fr'(?:–ò—Ç–æ–≥–æ\s—Å—É–º–º–∞\s—á–µ–∫–∞)\s*[:\s.]*\s*{AMOUNT_REGEX}', 'flags': re.IGNORECASE},
        {'tier': 1, 'desc': '–°—É–º–º–∞ —Å —è–≤–Ω—ã–º –∑–Ω–∞–∫–æ–º "+" –∏ —Å–∏–º–≤–æ–ª–æ–º –≤–∞–ª—é—Ç—ã', 'regex': fr'\+\s*{AMOUNT_REGEX}\s*{CURRENCY_REGEX}', 'flags': re.IGNORECASE},
        {'tier': 2, 'desc': '–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ "–°—É–º–º–∞/–ò—Ç–æ–≥–æ/–í—Å–µ–≥–æ/–î–æ–ª–≥" –∏ —á–∏—Å–ª–æ', 'regex': fr'(?:–°—É–º–º–∞|–ò—Ç–æ–≥–æ|–í—Å–µ–≥–æ|–ö\s–æ–ø–ª–∞—Ç–µ|–ü–æ–ø–æ–ª–Ω–µ–Ω–∏–µ|–ü–µ—Ä–µ–≤–æ–¥|–î–æ–ª–≥\s–ø–æ—Å–ª–µ\s–æ–ø–ª–∞—Ç—ã)\s*[:\s.]*\s*{AMOUNT_REGEX}', 'flags': re.IGNORECASE},
        {'tier': 3, 'desc': '–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ –í–´–®–ï —á–∏—Å–ª–∞', 'regex': fr'(?:–°—É–º–º–∞|–ò—Ç–æ–≥–æ|–í—Å–µ–≥–æ|–û–ø–µ—Ä–∞—Ü–∏—è|–°—É–º–º–∞\s–≤\s–≤–∞–ª—é—Ç–µ\s–æ–ø–µ—Ä–∞—Ü–∏–∏)\s*\n+\s*{AMOUNT_REGEX}\s*{CURRENCY_REGEX}?', 'flags': re.IGNORECASE},
        {'tier': 4, 'desc': '–ß–∏—Å–ª–æ —Å —è–≤–Ω—ã–º —Å–∏–º–≤–æ–ª–æ–º –≤–∞–ª—é—Ç—ã', 'regex': fr'\b{AMOUNT_REGEX}\s*{CURRENCY_REGEX}\b', 'flags': re.IGNORECASE},
        {'tier': 5, 'desc': '–ß–∏—Å–ª–æ —Å –∫–æ–ø–µ–π–∫–∞–º–∏ (—Ñ–æ—Ä–º–∞—Ç: 1234.56)', 'regex': r'\b(\d(?:\s?\d)*[,.]\d{2})\b', 'flags': 0},
    ]

def _get_bank_patterns() -> list:
    BANK_KEYWORDS = {
        '–¢-–ë–∞–Ω–∫': ['—Ç-–±–∞–Ω–∫', '—Ç–±–∞–Ω–∫', '—Ç–∏–Ω—å–∫–æ—Ñ—Ñ', 'tinkoff', 't-bank'],
        '–°–±–µ—Ä–±–∞–Ω–∫': ['—Å–±–µ—Ä–±–∞–Ω–∫', '—Å–±–µ—Ä', 'sber', 'sberbank'],
        '–ê–ª—å—Ñ–∞-–ë–∞–Ω–∫': ['–∞–ª—å—Ñ–∞-–±–∞–Ω–∫', '–∞–ª—å—Ñ–∞', 'alfa', 'alfabank'],
        '–í–¢–ë': ['–≤—Ç–±', 'vtb'],
        '–Ø–Ω–¥–µ–∫—Å': ['—è–Ω–¥–µ–∫—Å', 'yandex'],
    }
    patterns = []
    for bank_name, keywords in BANK_KEYWORDS.items():
        regex = r'\b(' + '|'.join(keywords) + r')\b'
        patterns.append({'tier': 1, 'desc': f'–ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –¥–ª—è "{bank_name}"', 'regex': regex, 'bank_name': bank_name, 'flags': re.IGNORECASE})
    return patterns

def _get_author_patterns(transaction_type: str) -> list:
    AUTHOR_NAME_REGEX = r'([–ê-–Ø–Å][–∞-—è—ëA-Za-z\s."¬´¬ª-]+?)'

    if transaction_type in ['income', 'transaction']:
        return [
            {'tier': 1, 'desc': '–ö–ª—é—á "–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å", "–ü–ª–∞—Ç–µ–ª—å—â–∏–∫", "–û—Ç –∫–æ–≥–æ"', 'regex': fr'(?:–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å|–ü–ª–∞—Ç–µ–ª—å—â–∏–∫|–û—Ç\s–∫–æ–≥–æ)\s*[:\s\n]*{AUTHOR_NAME_REGEX}(?=\n|$)', 'flags': re.IGNORECASE},
            {'tier': 2, 'desc': '–ò–º—è –ø–æ—Å–ª–µ —Å–ª–æ–≤–∞ "–û–ø–∏—Å–∞–Ω–∏–µ"', 'regex': r'–û–ø–∏—Å–∞–Ω–∏–µ[\s\n]+([–ê-–Ø–Å–∞-—è—ë\s]+\s[–ê-–Ø–Å]\.)', 'flags': re.IGNORECASE},
            {'tier': 3, 'desc': '–ò–º—è —Ñ–æ—Ä–º–∞—Ç–∞ (–ò–º—è –û.) –ø–æ—Å–ª–µ —Å—Ç—Ä–æ–∫–∏ —Å —Å—É–º–º–æ–π', 'regex': r'\b(?:\d[\d\s,.]*)\s*(?:–†|‚ÇΩ|—Ä—É–±\.?|RUB|P)[\s\n]+([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+)?\s+[–ê-–Ø–Å]\.)', 'flags': re.IGNORECASE},
            {'tier': 4, 'desc': '–ê–Ω–≥–ª–∏–π—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã: "From", "Sender"', 'regex': fr'(?:From|Sender)\s*[:\s\n]*{AUTHOR_NAME_REGEX}(?=\n|$)', 'flags': re.IGNORECASE},
            {'tier': 5, 'desc': '–§–æ—Ä–º–∞—Ç "–ò–º—è –û." –∏–ª–∏ "–ò–º—è –û—Ç—á–µ—Å—Ç–≤–æ –û."', 'regex': r'\b([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+){0,2}\s+[–ê-–Ø–Å]\.)\b', 'flags': 0},
        ]
    else: # expense
        return [
            {'tier': 0, 'desc': '–ù–∞–∑–≤–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –≤ –Ω–∞—á–∞–ª–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–Ω–∞–¥ –∞–¥—Ä–µ—Å–æ–º)', 'regex': r'^(.*?)\n\s*(?:–ê–¥—Ä–µ—Å\s–∫–ª–∏–Ω–∏–∫–∏|–ê–¥—Ä–µ—Å)', 'flags': re.MULTILINE},
            {'tier': 1, 'desc': '–ù–∞–∑–≤–∞–Ω–∏–µ –≤ –∫–∞–≤—ã—á–∫–∞—Ö: ¬´–û–û–û –†–æ–º–∞—à–∫–∞¬ª', 'regex': r'[¬´"]([^¬ª"]{3,})[¬ª"]', 'flags': 0},
            {'tier': 1, 'desc': '–ö–ª—é—á "–ü–æ–ª—É—á–∞—Ç–µ–ª—å", "–ü—Ä–æ–¥–∞–≤–µ—Ü"', 'regex': fr'(?:–ü–æ–ª—É—á–∞—Ç–µ–ª—å|–ü—Ä–æ–¥–∞–≤–µ—Ü|–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è)\s*[:\s\n]*{AUTHOR_NAME_REGEX}(?=\n|$)', 'flags': re.IGNORECASE},
            {'tier': 2, 'desc': '–û—Ä–≥. —Ñ–æ—Ä–º–∞: –û–û–û, –ò–ü, –ê–û', 'regex': r'\b(?:–û–û–û|–ò–ü|–ê–û|–ü–ê–û)\s+[¬´"]?([^¬ª"\n]{3,40})[¬ª"]?', 'flags': re.IGNORECASE},
        ]

def _get_comment_patterns() -> list:
    return [{'tier': 1, 'desc': '–ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º', 'regex': r'(?:–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π|–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ|–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ\s–ø–ª–∞—Ç–µ–∂–∞|Note|Comment|Description)\s*[:\s\n]*(.+?)(?=\n\n|$|\n\s*‚Äî{3,})', 'flags': re.IGNORECASE | re.DOTALL}]

def _get_procedure_patterns() -> list:
    return [{'tier': 1, 'desc': '–ë–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞ –º–µ–∂–¥—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–º —Ç–∞–±–ª–∏—Ü—ã –∏ –∏—Ç–æ–≥–æ–≤–æ–π —Å—É–º–º–æ–π', 'regex': r'(?:–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ.*?–°—Ç-—Ç—å)\s*\n(.*?)(?=\n\s*–ò—Ç–æ–≥–æ\s—Å—É–º–º–∞\s—á–µ–∫–∞)', 'flags': re.DOTALL | re.IGNORECASE}]

def parse_date(text: str) -> str | None:
    patterns = _get_date_patterns()
    MONTHS_RU = {'—è–Ω–≤–∞—Ä—è': '01', '—Ñ–µ–≤—Ä–∞–ª—è': '02', '–º–∞—Ä—Ç–∞': '03', '–∞–ø—Ä–µ–ª—è': '04', '–º–∞—è': '05', '–∏—é–Ω—è': '06', '–∏—é–ª—è': '07', '–∞–≤–≥—É—Å—Ç–∞': '08', '—Å–µ–Ω—Ç—è–±—Ä—è': '09', '–æ–∫—Ç—è–±—Ä—è': '10', '–Ω–æ—è–±—Ä—è': '11', '–¥–µ–∫–∞–±—Ä—è': '12'}
    MONTHS_EN = {'january': '01', 'february': '02', 'march': '03', 'april': '04', 'may': '05', 'june': '06', 'july': '07', 'august': '08', 'september': '09', 'october': '10', 'november': '11', 'december': '12'}

    found_dates = []
    
    for p in patterns:
        matches = list(re.finditer(p['regex'], text, p['flags']))
        for match in matches:
            try:
                dt_obj = None
                if p.get('type') == 'textual_ru':
                    day, month_name, year = match.groups()
                    month = MONTHS_RU.get(month_name.lower())
                    if month: 
                        dt_obj = datetime.strptime(f"{day}.{month}.{year}", "%d.%m.%Y")

                elif p.get('type') == 'textual_en':
                    day, month_name = match.groups()
                    month = MONTHS_EN.get(month_name.lower())
                    year = datetime.now().year
                    if month: 
                        dt_obj = datetime.strptime(f"{day}.{month}.{year}", "%d.%m.%Y")

                elif p.get('type') == 'numeric':
                    date_str = match.group(1).replace('/', '.').replace('-', '.')
                    parts = date_str.split('.')
                    year_format = "%Y" if len(parts[2]) == 4 else "%y"
                    dt_obj = datetime.strptime(date_str, f"%d.%m.{year_format}")

                if dt_obj:
                    normalized_date = dt_obj.strftime("%d.%m.%Y")
                    found_dates.append({
                        'date': normalized_date,
                        'tier': p['tier'],
                        'match_text': match.group(0),
                        'position': match.start()
                    })
            except (ValueError, IndexError) as e:
                continue

    if found_dates:
        best_date = min(found_dates, key=lambda x: (x['tier'], x['position']))
        return best_date['date']
    
    return None

def parse_amount(text: str, transaction_type: str) -> float | None:
    patterns = _get_amount_patterns()
    for p in patterns:
        match = re.search(p['regex'], text, p['flags'])
        if match:
            amount_str = match.groups()[-1]
            amount = _clean_amount_string(amount_str)
            if amount and amount > 0:
                return amount
    return None

def parse_bank(text: str) -> str | None:
    patterns = _get_bank_patterns()
    search_text = text.lower()
    for p in patterns:
        if re.search(p['regex'], search_text, p['flags']):
            bank_name = p['bank_name']
            return bank_name
    return None

def parse_author(text: str, transaction_type: str) -> str | None:
    patterns = _get_author_patterns(transaction_type)
    STOPWORDS = ['—É–ª–∏—Ü–∞', '–º–æ—Å–∫–≤–∞', '—Ä–æ—Å—Å–∏—è', '–∫–∞—Å—Å–∏—Ä', '—á–µ–∫', '–¥–æ–∫—É–º–µ–Ω—Ç',
                 '–æ–ø–µ—Ä–∞—Ü–∏—è', '–ø–ª–∞—Ç–µ–∂', '–∫–∞—Ä—Ç–∞', '—Å—á–µ—Ç', 'transaction', '—É—Å–ø–µ—à–Ω–æ']
    for p in patterns:
        matches = list(re.finditer(p['regex'], text, p['flags']))
        for match in matches:
            author = ' '.join(filter(None, match.groups())).strip()
            author = _clean_author_string(author)
            if len(author) < 2 or len(author) > 50: continue
            if any(stop in author.lower() for stop in STOPWORDS): continue
            if re.fullmatch(r'[\d\s.,]+', author): continue
            return author
    return None

def parse_comment(text: str) -> str | None:
    patterns = _get_comment_patterns()
    for p in patterns:
        match = re.search(p['regex'], text, p['flags'])
        if match:
            comment = match.group(1).strip().replace('\n', ' ')
            if len(comment) > 2:
                comment = comment[:200] + '...' if len(comment) > 200 else comment
                return comment
    return None

def parse_procedure(text: str) -> str | None:
    patterns = _get_procedure_patterns()
    for p in patterns:
        match = re.search(p['regex'], text, p['flags'])
        if match:
            procedures_block = match.group(1).strip()
            clean_lines = []
            
            for line in procedures_block.split('\n'):
                line = line.strip()
                if not line:
                    continue
                
                cleaned_line = re.sub(r'[\s\d,.]+(—Ä—É–±\.?)?$', '', line).strip()
                cleaned_line = re.sub(r'\s*\([^)]*\)', '', cleaned_line).strip()
                
                if len(cleaned_line) > 2 and re.search(r'[–∞-—è–ê-–Ø]', cleaned_line):
                    clean_lines.append(cleaned_line)
            
            if clean_lines:
                result = '; '.join(clean_lines)
                return result
    return None

def parse_multiple_transactions(text: str) -> list[dict]:
    """
    –ü–∞—Ä—Å–∏—Ç –±–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–æ—Ö–æ–¥–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π —Å–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞.
    –õ–æ–≥–∏–∫–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ –ø–æ—Å—Ç—Ä–æ—á–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ.
    """
    logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π. –û–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤.")
    
    bank = parse_bank(text)
    transactions = []
    lines = [line.strip() for line in text.split('\n') if line.strip()]

    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—É–º–º—ã (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "+", —Å–æ–¥–µ—Ä–∂–∏—Ç —Ü–∏—Ñ—Ä—ã, –ø—Ä–æ–±–µ–ª—ã, –∑–∞–ø—è—Ç—ã–µ/—Ç–æ—á–∫–∏ –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è "–†" –∏–ª–∏ "‚ÇΩ")
    amount_pattern = re.compile(r'^\+\s*([\d\s,.]+)\s*(?:‚ÇΩ|–†)$')
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–º–µ–Ω–∏ (–ò–º—è –§–∞–º–∏–ª–∏—è/–ë—É–∫–≤–∞. - –Ω–∞–ø—Ä–∏–º–µ—Ä, "–†—É—Å—Ç–∞–º –•" –∏–ª–∏ "–¢–∞–º–∏—Ä–ª–∞–Ω –®.")
    author_pattern = re.compile(r'^[–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å]\.?$')

    for i, line in enumerate(lines):
        amount_match = amount_pattern.search(line)
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—É–º–º—É –¥–æ—Ö–æ–¥–∞
        if amount_match:
            amount_str = amount_match.group(1)
            amount = _clean_amount_string(amount_str)
            
            author = None
            # –ò—â–µ–º –∞–≤—Ç–æ—Ä–∞ –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö. –ù–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞—Ö –¢-–ë–∞–Ω–∫–∞ –æ–Ω –æ–±—ã—á–Ω–æ –Ω–∞ 2 —Å—Ç—Ä–æ–∫–∏ –≤—ã—à–µ.
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å i-1 –ø–æ i-3, —á—Ç–æ–±—ã –±—ã—Ç—å –±–æ–ª–µ–µ –≥–∏–±–∫–∏–º–∏ –∫ –æ—à–∏–±–∫–∞–º OCR
            if i > 0:
                # –í —Å–∫—Ä–∏–Ω—à–æ—Ç–µ –¢-–ë–∞–Ω–∫–∞ –∏–º—è –Ω–∞—Ö–æ–¥–∏—Ç—Å—è —á–µ—Ä–µ–∑ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –≤—ã—à–µ (i-2)
                # –ü—Ä–∏–º–µ—Ä:
                # [i-2]: –¢–∞–º–∏—Ä–ª–∞–Ω –®.  <- –ò–º—è
                # [i-1]: Transfers    <- –¢–∏–ø
                # [i]:   +200 –†       <- –°—É–º–º–∞
                if i >= 2 and author_pattern.match(lines[i-2]):
                    author = lines[i-2]
                # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç: –∏—â–µ–º –Ω–∞ —Å—Ç—Ä–æ–∫–µ –ø—Ä—è–º–æ –ø–µ—Ä–µ–¥ —Å—É–º–º–æ–π
                elif author_pattern.match(lines[i-1]):
                     author = lines[i-1]


            if author and amount:
                transactions.append({
                    'author': _clean_author_string(author),
                    'amount': amount,
                    'bank': bank if bank else "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
                })

    logger.info(f"üìä –ü–∞—Ä—Å–∏–Ω–≥ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω. –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {len(transactions)} –∑–∞–ø–∏—Å–µ–π.")
    return transactions


def parse_transaction_data(text: str, transaction_type: str) -> dict:
    logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥. –¢–∏–ø: {transaction_type.upper()}. –û–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤.")
    
    result = {
        "date": parse_date(text),
        "amount": parse_amount(text, transaction_type),
    }

    if transaction_type in ['income', 'transaction']:
        normalized_text = _normalize_text_for_search(text)
        result['bank'] = parse_bank(normalized_text)
        result['author'] = parse_author(normalized_text, transaction_type)
        result['comment'] = parse_comment(normalized_text)
    else: # expense
        result['procedure'] = parse_procedure(text)
        result['author'] = parse_author(text, transaction_type)
        result['comment'] = parse_comment(text)

    filled_fields = sum(1 for v in result.values() if v is not None)
    total_fields = len(result)
    logger.info(
        f"üìä –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. "
        f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ –ø–æ–ª–µ–π: {filled_fields}/{total_fields}. "
        f"–ò—Ç–æ–≥: {result}"
    )
    return result