import re
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

def _clean_amount_string(s: str) -> float | None:
    if not isinstance(s, str): return None
    try:
        cleaned = re.sub(r'[^\d,.]', '', s).replace(',', '.')
        return float(cleaned)
    except (ValueError, TypeError): return None

def _normalize_text_for_search(text: str) -> str:
    if not isinstance(text, str): return ''
    text = re.sub(r'[ \t]+', ' ', text)
    text = re.sub(r'\n+', '\n', text)
    return text.strip()

def _clean_author_string(author: str) -> str:
    author = author.strip('.,;:"¬´¬ª \n\t')
    author = re.sub(r'^(–û–û–û|–ò–ü|–ê–û|–ü–ê–û|–ó–ê–û|–û–ê–û)\s+', '', author, flags=re.IGNORECASE).strip()
    return author.strip('"¬´¬ª')

def _get_date_patterns() -> list:
    return [
        {'tier': 0, 'desc': '–î–∞—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –≤—Ä–µ–º–µ–Ω–µ–º (—Ç–µ–∫—Å—Ç–æ–≤–∞—è, —Å –∫–ª—é—á–æ–º)', 'regex': r'(?:–û–ø–µ—Ä–∞—Ü–∏—è\s+—Å–æ–≤–µ—Ä—à–µ–Ω–∞|–î–∞—Ç–∞\s+–æ–ø–µ—Ä–∞—Ü–∏–∏|–¢–æ–≤–∞—Ä–Ω—ã–π\s—á–µ–∫\s.*?–∑–∞)[:\s]*(\d{1,2})\s+(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)\s+(\d{4})', 'type': 'textual_ru', 'flags': re.IGNORECASE},
        {'tier': 0, 'desc': '–î–∞—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –≤—Ä–µ–º–µ–Ω–µ–º (—á–∏—Å–ª–æ–≤–∞—è, —Å –∫–ª—é—á–æ–º)', 'regex': r'(?:–û–ø–µ—Ä–∞—Ü–∏—è\s+—Å–æ–≤–µ—Ä—à–µ–Ω–∞|–î–∞—Ç–∞\s+–æ–ø–µ—Ä–∞—Ü–∏–∏)[:\s]*(\d{2}[./-]\d{2}[./-]\d{2,4})(?:\s+–≤\s+\d{1,2}:\d{2})?', 'type': 'numeric', 'flags': re.IGNORECASE},
        {'tier': 1, 'desc': '–î–∞—Ç–∞ —Ä—è–¥–æ–º —Å —Å—É–º–º–æ–π –∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–º', 'regex': r'(?:–ü–µ—Ä–µ–≤–æ–¥|–ó–∞—á–∏—Å–ª–µ–Ω–∏–µ|–°–ø–∏—Å–∞–Ω–∏–µ)\s+–æ—Ç?\s*(\d{1,2})\s+(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)\s+(\d{4})', 'type': 'textual_ru', 'flags': re.IGNORECASE},
        {'tier': 1, 'desc': '–î–∞—Ç–∞ —Ä—è–¥–æ–º —Å —Å—É–º–º–æ–π –∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–º (—á–∏—Å–ª–æ–≤–∞—è)', 'regex': r'(?:–ü–µ—Ä–µ–≤–æ–¥|–ó–∞—á–∏—Å–ª–µ–Ω–∏–µ|–°–ø–∏—Å–∞–Ω–∏–µ)\s+–æ—Ç?\s*(\d{2}[./-]\d{2}[./-]\d{2,4})', 'type': 'numeric', 'flags': re.IGNORECASE},
        {'tier': 3, 'desc': '–õ—é–±–∞—è –¥–∞—Ç–∞ –≤ —á–∏—Å–ª–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (–î–î.–ú–ú.–ì–ì–ì–ì)', 'regex': r'\b(\d{2}[./-]\d{2}[./-]\d{2,4})\b', 'type': 'numeric', 'flags': 0}
    ]

def _get_amount_patterns() -> list:
    AMOUNT_REGEX = r'(\d(?:\s?\d)*(?:[,.]\d{1,2})?)'
    CURRENCY_REGEX = r'(?:–†|‚ÇΩ|—Ä—É–±\.?|RUB|P)'
    return [
        {'tier': 0, 'desc': '–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ "–ò—Ç–æ–≥–æ —Å—É–º–º–∞ —á–µ–∫–∞"', 'regex': fr'(?:–ò—Ç–æ–≥–æ\s—Å—É–º–º–∞\s—á–µ–∫–∞)\s*[:\s.]*\s*{AMOUNT_REGEX}', 'flags': re.IGNORECASE},
        {'tier': 1, 'desc': '–°—É–º–º–∞ —Å —è–≤–Ω—ã–º –∑–Ω–∞–∫–æ–º "+" –∏ —Å–∏–º–≤–æ–ª–æ–º –≤–∞–ª—é—Ç—ã', 'regex': fr'\+\s*{AMOUNT_REGEX}\s*{CURRENCY_REGEX}', 'flags': re.IGNORECASE},
        {'tier': 2, 'desc': '–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ "–°—É–º–º–∞/–ò—Ç–æ–≥–æ/–í—Å–µ–≥–æ/–î–æ–ª–≥"', 'regex': fr'(?:–°—É–º–º–∞|–ò—Ç–æ–≥–æ|–í—Å–µ–≥–æ|–ö\s–æ–ø–ª–∞—Ç–µ|–ü–æ–ø–æ–ª–Ω–µ–Ω–∏–µ|–ü–µ—Ä–µ–≤–æ–¥|–î–æ–ª–≥\s–ø–æ—Å–ª–µ\s–æ–ø–ª–∞—Ç—ã)\s*[:\s.]*\s*{AMOUNT_REGEX}', 'flags': re.IGNORECASE},
        {'tier': 4, 'desc': '–ß–∏—Å–ª–æ —Å —è–≤–Ω—ã–º —Å–∏–º–≤–æ–ª–æ–º –≤–∞–ª—é—Ç—ã', 'regex': fr'\b{AMOUNT_REGEX}\s*{CURRENCY_REGEX}\b', 'flags': re.IGNORECASE},
        {'tier': 5, 'desc': '–ß–∏—Å–ª–æ —Å –∫–æ–ø–µ–π–∫–∞–º–∏ (—Ñ–æ—Ä–º–∞—Ç: 1234.56)', 'regex': r'\b(\d(?:\s?\d)*[,.]\d{2})\b', 'flags': 0},
    ]

def _get_bank_patterns() -> list:
    BANK_KEYWORDS = {'–¢-–ë–∞–Ω–∫': ['—Ç-–±–∞–Ω–∫', '—Ç–±–∞–Ω–∫', '—Ç–∏–Ω—å–∫–æ—Ñ—Ñ', 'tinkoff', 't-bank'], '–°–±–µ—Ä–±–∞–Ω–∫': ['—Å–±–µ—Ä–±–∞–Ω–∫', '—Å–±–µ—Ä', 'sber', 'sberbank'], '–ê–ª—å—Ñ–∞-–ë–∞–Ω–∫': ['–∞–ª—å—Ñ–∞-–±–∞–Ω–∫', '–∞–ª—å—Ñ–∞', 'alfa', 'alfabank'], '–í–¢–ë': ['–≤—Ç–±', 'vtb']}
    return [{'tier': 1, 'desc': f'–ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –¥–ª—è "{bank_name}"', 'regex': r'\b(' + '|'.join(keywords) + r')\b', 'bank_name': bank_name, 'flags': re.IGNORECASE} for bank_name, keywords in BANK_KEYWORDS.items()]

def _get_author_patterns(transaction_type: str) -> list:
    AUTHOR_NAME_REGEX = r'([–ê-–Ø–Å][–∞-—è—ëA-Za-z\s."¬´¬ª-]+?)'
    if transaction_type in ['income', 'transaction']:
        return [
            {'tier': 1, 'desc': '–ö–ª—é—á "–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å", "–ü–ª–∞—Ç–µ–ª—å—â–∏–∫", "–û—Ç –∫–æ–≥–æ"', 'regex': fr'(?:–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å|–ü–ª–∞—Ç–µ–ª—å—â–∏–∫|–û—Ç\s–∫–æ–≥–æ)\s*[:\s\n]*{AUTHOR_NAME_REGEX}(?=\n|$)', 'flags': re.IGNORECASE},
            {'tier': 3, 'desc': '–ò–º—è —Ñ–æ—Ä–º–∞—Ç–∞ (–ò–º—è –û.) –ø–æ—Å–ª–µ —Å—Ç—Ä–æ–∫–∏ —Å —Å—É–º–º–æ–π', 'regex': r'\b(?:\d[\d\s,.]*)\s*(?:–†|‚ÇΩ|—Ä—É–±\.?|RUB|P)[\s\n]+([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+)?\s+[–ê-–Ø–Å]\.)', 'flags': re.IGNORECASE},
            {'tier': 5, 'desc': '–§–æ—Ä–º–∞—Ç "–ò–º—è –û." –∏–ª–∏ "–ò–º—è –û—Ç—á–µ—Å—Ç–≤–æ –û."', 'regex': r'\b([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+){0,2}\s+[–ê-–Ø–Å]\.)\b', 'flags': 0},
        ]
    else:
        return [
            {'tier': 1, 'desc': '–ù–∞–∑–≤–∞–Ω–∏–µ –≤ –∫–∞–≤—ã—á–∫–∞—Ö: ¬´–û–û–û –†–æ–º–∞—à–∫–∞¬ª', 'regex': r'[¬´"]([^¬ª"]{3,})[¬ª"]', 'flags': 0},
            {'tier': 1, 'desc': '–ö–ª—é—á "–ü–æ–ª—É—á–∞—Ç–µ–ª—å", "–ü—Ä–æ–¥–∞–≤–µ—Ü"', 'regex': fr'(?:–ü–æ–ª—É—á–∞—Ç–µ–ª—å|–ü—Ä–æ–¥–∞–≤–µ—Ü|–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è)\s*[:\s\n]*{AUTHOR_NAME_REGEX}(?=\n|$)', 'flags': re.IGNORECASE},
            {'tier': 2, 'desc': '–û—Ä–≥. —Ñ–æ—Ä–º–∞: –û–û–û, –ò–ü, –ê–û', 'regex': r'\b(?:–û–û–û|–ò–ü|–ê–û|–ü–ê–û)\s+[¬´"]?([^¬ª"\n]{3,40})[¬ª"]?', 'flags': re.IGNORECASE},
        ]

def _get_comment_patterns() -> list:
    return [{'tier': 1, 'desc': '–ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º', 'regex': r'(?:–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π|–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ|–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ\s–ø–ª–∞—Ç–µ–∂–∞|Note|Comment|Description)\s*[:\s\n]*(.+?)(?=\n\n|$|\n\s*‚Äî{3,})', 'flags': re.IGNORECASE | re.DOTALL}]

def _get_procedure_patterns() -> list:
    return [{'tier': 1, 'desc': '–ë–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞ –º–µ–∂–¥—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–º —Ç–∞–±–ª–∏—Ü—ã –∏ –∏—Ç–æ–≥–æ–≤–æ–π —Å—É–º–º–æ–π', 'regex': r'(?:–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ.*?–°—Ç-—Ç—å)\s*\n(.*?)(?=\n\s*–ò—Ç–æ–≥–æ\s—Å—É–º–º–∞\s—á–µ–∫–∞)', 'flags': re.DOTALL | re.IGNORECASE}]

def parse_date(text: str) -> str | None:
    patterns = _get_date_patterns()
    MONTHS_RU = {'—è–Ω–≤–∞—Ä—è': '01', '—Ñ–µ–≤—Ä–∞–ª—è': '02', '–º–∞—Ä—Ç–∞': '03', '–∞–ø—Ä–µ–ª—è': '04', '–º–∞—è': '05', '–∏—é–Ω—è': '06', '–∏—é–ª—è': '07', '–∞–≤–≥—É—Å—Ç–∞': '08', '—Å–µ–Ω—Ç—è–±—Ä—è': '09', '–æ–∫—Ç—è–±—Ä—è': '10', '–Ω–æ—è–±—Ä—è': '11', '–¥–µ–∫–∞–±—Ä—è': '12'}
    for p in patterns:
        for match in re.finditer(p['regex'], text, p['flags']):
            try:
                dt_obj = None
                if p.get('type') == 'textual_ru':
                    day, month_name, year = match.groups()
                    dt_obj = datetime.strptime(f"{day}.{MONTHS_RU[month_name.lower()]}.{year}", "%d.%m.%Y")
                elif p.get('type') == 'numeric':
                    date_str = match.group(1).replace('/', '.').replace('-', '.')
                    year_format = "%Y" if len(date_str.split('.')[2]) == 4 else "%y"
                    dt_obj = datetime.strptime(date_str, f"%d.%m.{year_format}")
                if dt_obj: return dt_obj.strftime("%d.%m.%Y")
            except (ValueError, IndexError): continue
    return None

def parse_amount(text: str, transaction_type: str) -> float | None:
    for p in _get_amount_patterns():
        if match := re.search(p['regex'], text, p['flags']):
            if amount := _clean_amount_string(match.groups()[-1]): return amount
    return None

def parse_bank(text: str) -> str | None:
    search_text = text.lower()
    for p in _get_bank_patterns():
        if re.search(p['regex'], search_text, p['flags']): return p['bank_name']
    return None

def parse_author(text: str, transaction_type: str) -> str | None:
    STOPWORDS = ['—É–ª–∏—Ü–∞', '–º–æ—Å–∫–≤–∞', '—Ä–æ—Å—Å–∏—è', '–∫–∞—Å—Å–∏—Ä', '—á–µ–∫', '–æ–ø–µ—Ä–∞—Ü–∏—è', '–ø–ª–∞—Ç–µ–∂', '–∫–∞—Ä—Ç–∞', '—Å—á–µ—Ç']
    for p in _get_author_patterns(transaction_type):
        for match in re.finditer(p['regex'], text, p['flags']):
            author = _clean_author_string(' '.join(filter(None, match.groups())).strip())
            if 2 < len(author) < 50 and not any(stop in author.lower() for stop in STOPWORDS) and not re.fullmatch(r'[\d\s.,]+', author):
                return author
    return None

def parse_comment(text: str) -> str | None:
    for p in _get_comment_patterns():
        if match := re.search(p['regex'], text, p['flags']):
            comment = match.group(1).strip().replace('\n', ' ')
            if len(comment) > 2: return comment[:200]
    return None

def parse_procedure(text: str) -> str | None:
    for p in _get_procedure_patterns():
        if match := re.search(p['regex'], text, p['flags']):
            lines = [re.sub(r'[\s\d,.]+(—Ä—É–±\.?)?$', '', line).strip() for line in match.group(1).strip().split('\n') if line.strip()]
            if clean_lines := [re.sub(r'\s*\([^)]*\)', '', l).strip() for l in lines if len(l) > 2 and re.search(r'[–∞-—è–ê-–Ø]', l)]:
                return '; '.join(clean_lines)
    return None

def _parse_multiple_transactions(text: str) -> list[dict]:
    pattern = re.compile(r'([–ê-–Ø–Å–∞-—è—ë\s]+\s[–ê-–Ø–Å]\.)\n(?:Transfers|Top-ups).*?\+\s*([\d\s,.]+)\s*–†', re.MULTILINE)
    transactions = []
    for match in pattern.finditer(text):
        author, amount_str = match.groups()
        if (amount := _clean_amount_string(amount_str)):
            transactions.append({'author': author.strip(), 'amount': amount})
    return transactions

def parse_transaction_data(text: str, transaction_type: str) -> dict:
    logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥. –¢–∏–ø: {transaction_type.upper()}. –û–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤.")
    normalized_text = _normalize_text_for_search(text)
    
    if transaction_type == 'transaction':
        result = {
            "transactions": _parse_multiple_transactions(normalized_text),
            "bank": parse_bank(normalized_text),
            "comment": parse_comment(normalized_text)
        }
    else:
        result = {
            "date": parse_date(text),
            "amount": parse_amount(text, transaction_type),
            "author": parse_author(normalized_text, transaction_type),
            "comment": parse_comment(normalized_text),
        }
        if transaction_type == 'income':
            result['bank'] = parse_bank(normalized_text)
        else:
            result['procedure'] = parse_procedure(text)
    
    logger.info(f"üìä –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ò—Ç–æ–≥: {result}")
    return result